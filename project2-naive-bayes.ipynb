{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIS 678 - Machine Learning\n",
    "\n",
    "## Programming Project 2 - Naive Bayes Classifier\n",
    "\n",
    "### Julian Carrasquillo, 1/22/20\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specification\n",
    "\n",
    "The idea is to write a program that, when given a collection of training data consisting of labeled (`Spam` | `Ham`) text messages, “learns” how to classify (or tag) new messages correctly using a Naïve Bayes classifier. Said differently, write a spam filter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background\n",
    "\n",
    "The Naïve Bayes algorithm uses probabilities to perform classification. The probabilities are estimated based on training data for which the value of the classification is known (i.e. it is a form of Supervised Learning). The algorithm is called “naïve” because it makes the simplifying assumption that attribute values are completely independent, given the classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data set\n",
    "\n",
    "The data consists of a collection of 5574 labeled SMS text messages in a zipped format. Format consists of 2 columns: classification and full unprocessed text message. \n",
    "  \n",
    "Normally, we can use `pandas` to read in zip files directly, but this particular folder contains multiple files. We will use `zipfile` to handle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flag</th>\n",
       "      <th>msg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5567</td>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5568</td>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5569</td>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5570</td>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5571</td>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      flag                                                msg\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568   ham               Will ü b going to esplanade fr home?\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...\n",
       "5570   ham  The guy did some bitching but I acted like i'd...\n",
       "5571   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from zipfile import ZipFile\n",
    "import pandas as pd\n",
    "\n",
    "with ZipFile('data/smsspamcollection.zip', 'r') as zip:\n",
    "    zip.extractall(path = 'data/') \n",
    "    \n",
    "sms = pd.read_table('data/SMSSpamCollection', names = ['flag', 'msg'])\n",
    "\n",
    "sms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can explore the dimensions of our data set, specifically around the counts of our two classifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msg</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flag</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>ham</td>\n",
       "      <td>4825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>spam</td>\n",
       "      <td>747</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       msg\n",
       "flag      \n",
       "ham   4825\n",
       "spam   747"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms.groupby('flag').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most messages in our inboxes are **not** spam. This set represents the phenomenon that most of the time, the messages we receive are legitimate. It's also good to point that we have clean labels - there are no missing or mispelled indicators.\n",
    "  \n",
    "According to the `readme` file included with the data set, the text messages come from a few different sources. We should verify that our set consists of distinct messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Series.unique of 0       Go until jurong point, crazy.. Available only ...\n",
       "1                           Ok lar... Joking wif u oni...\n",
       "2       Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3       U dun say so early hor... U c already then say...\n",
       "4       Nah I don't think he goes to usf, he lives aro...\n",
       "                              ...                        \n",
       "5567    This is the 2nd time we have tried 2 contact u...\n",
       "5568                 Will ü b going to esplanade fr home?\n",
       "5569    Pity, * was in mood for that. So...any other s...\n",
       "5570    The guy did some bitching but I acted like i'd...\n",
       "5571                           Rofl. Its true to its name\n",
       "Name: msg, Length: 5572, dtype: object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms.msg.unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like our text samples are all unique. Good to go onto text processing!  \n",
    "  \n",
    "## Getting our Words\n",
    "  \n",
    "In order to analyze the words in each text message, we need a way to extract them. It's always good to use old code when appropriate, so we can go back to [project 1](https://github.com/cis678-w20/project1-carrasq/tree/master/project_1) and use `get_words` and `clean_text`. We will need to modify the code to handle single strings as opposed to reading a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words(text):\n",
    "    import re\n",
    "    total_words = [m.string[m.start():m.end()] for m in re.finditer(\"\\w+(\\s|\\.|!|\\?|,|:|;|\\\"|\\'|\\)|$)\", text)]\n",
    "    return total_words\n",
    "\n",
    "def clean_text(words):\n",
    "    import re\n",
    "    # remove leading punctuation and capital letters for visualizations\n",
    "    cleaned = []\n",
    "    for word in words:\n",
    "        word = re.sub(\"\\s|\\.|!|\\?|,|:|;|\\\"|\\'|\\)|$\", \"\", word)\n",
    "        cleaned.append(word.lower())\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Go ',\n",
       " 'until ',\n",
       " 'jurong ',\n",
       " 'point,',\n",
       " 'crazy.',\n",
       " 'Available ',\n",
       " 'only ',\n",
       " 'in ',\n",
       " 'bugis ',\n",
       " 'n ',\n",
       " 'great ',\n",
       " 'world ',\n",
       " 'la ',\n",
       " 'e ',\n",
       " 'buffet.',\n",
       " 'Cine ',\n",
       " 'there ',\n",
       " 'got ',\n",
       " 'amore ',\n",
       " 'wat.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(sms.msg[0])\n",
    "get_words(sms.msg[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can build our full vocabulary by looping through all of the text messages and combining the lists into a super list. After cleaning, we will have a full collection of words to support our naive bayes classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_vocab = []\n",
    "for msg in sms.msg:\n",
    "    full_vocab = full_vocab + get_words(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['go', 'until', 'jurong', 'point', 'crazy']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text(full_vocab)[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_clean = clean_text(full_vocab)\n",
    "\n",
    "# remove duplicates\n",
    "vocab_clean = list(set(vocab_clean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "  \n",
    "Before we calculate probabilities, we need to split the data into a training and testing set. We can use a random number generator to assign the groups. To make sure the training and test group have similar ratios of `spam` to `ham` as the whole population, we will use the random generator on each group separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set has 80.1% of the data.\n",
      "Test Set has 19.9% of the data.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1bce3ebb548>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# set seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# split out to build properly distributed training / test sets\n",
    "spam = sms[sms.flag == 'spam'].copy()\n",
    "ham = sms[sms.flag == 'ham'].copy()\n",
    "\n",
    "spam['random'] = np.random.uniform(0, 1, spam.shape[0])\n",
    "ham['random'] = np.random.uniform(0, 1, ham.shape[0])\n",
    "\n",
    "training = pd.concat([spam.loc[spam.random < 0.8], ham.loc[ham.random < 0.8]]).drop(['random'], axis = 1)\n",
    "test = pd.concat([spam.loc[spam.random >= 0.8], ham.loc[ham.random >= 0.8]]).drop(['random'], axis = 1)\n",
    "\n",
    "print(\"Training Set has %3.1f%% of the data.\" % (100*len(training)/len(sms)))\n",
    "print(\"Test Set has %3.1f%% of the data.\" % (100*len(test)/len(sms)))\n",
    "\n",
    "training.groupby('flag').count().plot(kind = 'bar')\n",
    "test.groupby('flag').count().plot(kind = 'bar')\n",
    "sms.groupby('flag').count().plot(kind = 'bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can build a function that will calculate the various metrics needed for the classifier. For a class $c_j$, we want \n",
    "\n",
    "* the number of training messages in that class, $msgs_j$\n",
    "* the probability estimate for a particular class,  \n",
    "$P(c_j) = \\frac{msgs_j}{msgs_{total}}$ \n",
    "* the total word bank from that class, $text_j$\n",
    "* the number of total word tokens in $text_j$, $n$\n",
    "\n",
    "From this, we can build out probabilities for every word $w_k$ in `full_vocab` given a specific class. For each we want\n",
    "\n",
    "* the number of times work $w_k$ appears in $text_j$, $n_k$\n",
    "* the estimate of the word occurance for a particular message type,  \n",
    "$P(w_k | c_j) = \\frac{n_k + 1}{n + |Vocabulary|}$\n",
    "  \n",
    "The added components in the probability estimate are a smoothing technique to handle any situations where a word in the test set was not found during training. Without this intervention, any message with a new word would yield a 0 probability.  \n",
    "  \n",
    "To count the members of a class, we can group the given table and build a dictionary. The below is a little more robust than needed, but it will be good to make this function more generalizeable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ham': 3872, 'spam': 592}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_classes(df, col):\n",
    "    counts = df.groupby(col).count()\n",
    "    counts_dict = {}\n",
    "    \n",
    "    for i in counts.index:\n",
    "        counts_dict.update({i : counts.loc[i][0]})\n",
    "    \n",
    "    return counts_dict\n",
    "        \n",
    "count_classes(training, 'flag')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get probability estimates, we can build on the `count_classes` function to also return percent of the total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_classes(df, col):\n",
    "    counts = df.groupby(col).count()\n",
    "    counts_dict = {}\n",
    "    # added total counter and probability dictionary\n",
    "    prob_dict = {}\n",
    "    total = 0\n",
    "    \n",
    "    for i in counts.index:\n",
    "        counts_dict.update({i : counts.loc[i][0]})\n",
    "        total = total + counts.loc[i][0]\n",
    "    \n",
    "    for i in counts.index:\n",
    "        prob_dict.update({i : counts.loc[i][0] / total})\n",
    "        \n",
    "    return (counts_dict, prob_dict)\n",
    "        \n",
    "class_counts, class_probs = count_classes(training, 'flag')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build the word bank, we use a modified version of the code used to build the full vocabulary. Specifically, we will do everything but remove the duplicates. We want to see *how often* a word appears in each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ham': 56389, 'spam': 14428}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_wordbank(text):\n",
    "    full_wordbank = []\n",
    "    for msg in text:\n",
    "        full_wordbank = full_wordbank + get_words(msg)\n",
    "    \n",
    "    return clean_text(full_wordbank)\n",
    "\n",
    "class_wordbanks = {}\n",
    "class_wordbanks_counts = {}\n",
    "for group in ['ham', 'spam']:\n",
    "    class_wordbanks.update({group : make_wordbank(training[training.flag == group].msg)})\n",
    "    class_wordbanks_counts.update({group : len(class_wordbanks[group])})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going through our distinct total vocabulary, `vocab_clean`, we can build an embedded dictionary to show the word's prominence in each class. An embedded dictionary packages each word's probabilities for each class, allowing us to access both after a single search. This gives the dictionary a `json`-like feel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_classed = {}\n",
    "for word in vocab_clean:\n",
    "    vocab_classed.update({word : {'ham' : class_wordbanks['ham'].count(word),\n",
    "                                 'spam': class_wordbanks['spam'].count(word)}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'82324': {'ham': 0, 'spam': 1},\n",
       " 'misplaced': {'ham': 0, 'spam': 0},\n",
       " 'new': {'ham': 51, 'spam': 52},\n",
       " 'onwords': {'ham': 1, 'spam': 0},\n",
       " 'cos': {'ham': 50, 'spam': 0}}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print first 5 dictionary entries\n",
    "{k: vocab_classed[k] for k in list(vocab_classed)[:5]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a similar technique to the above embedded dictionary, we can build out a lookup for the conditional probabilities of a work given each class. Multiplying many probabilities together yields a smaller and smaller output with more precision needed each time to differentiate 2 words. In order to not bring in an arbitrary precision library, we can instead take the **log of each probability** and add them together to find the more likely class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "vocab_probs = {}\n",
    "ham_length = len(class_wordbanks['ham'])\n",
    "spam_length = len(class_wordbanks['spam'])\n",
    "vocab_length = len(vocab_clean)\n",
    "\n",
    "for word in vocab_clean:\n",
    "    vocab_probs.update({word : {'ham' : math.log((vocab_classed[word]['ham'] + 1)/ (ham_length + vocab_length)),\n",
    "                                'spam': math.log((vocab_classed[word]['spam'] + 1)/ (spam_length + vocab_length))}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'82324': {'ham': -11.082157933374816, 'spam': -9.351839934249883},\n",
       " 'misplaced': {'ham': -11.082157933374816, 'spam': -10.044987114809828},\n",
       " 'new': {'ham': -7.130914214793389, 'spam': -6.074695201257706},\n",
       " 'onwords': {'ham': -10.38901075281487, 'spam': -10.044987114809828},\n",
       " 'cos': {'ham': -7.150332300650491, 'spam': -10.044987114809828}}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print first 5 dictionary entries\n",
    "{k: vocab_probs[k] for k in list(vocab_probs)[:5]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "Now we can take this learning and apply it to a new, never before seen data set. We set aside ~20% of our data for this purpose. A Naive Bayes classifier calculates the following for a given message:\n",
    "  \n",
    "$$\n",
    "    C_{NB} = max_{C}(P(c_j) \\Pi (P(a_i | c_j))\n",
    "$$\n",
    "\n",
    "Using the log transformation we implemented, we are interested in this iteration:\n",
    "\n",
    "$$\n",
    "    C_{NB} = max_{C}(log(P(c_j)) +  \\sum_{i} log(P(a_i | c_j)))\n",
    "$$\n",
    "\n",
    "Where $a_i$ is the ith word in a message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_nb(text):\n",
    "    import math\n",
    "    ham_prob = math.log(class_probs['ham'])\n",
    "    spam_prob = math.log(class_probs['spam'])\n",
    "    \n",
    "    for word in text:\n",
    "        found_word = vocab_probs[word]\n",
    "        ham_prob = ham_prob + found_word['ham']\n",
    "        spam_prob = spam_prob + found_word['spam']\n",
    "    \n",
    "    if ham_prob > spam_prob:\n",
    "        return 'ham'\n",
    "    else:\n",
    "        return 'spam'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['pred'] = test.msg.apply(get_words).apply(clean_text).apply(classify_nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because `spam` is much less common than `ham`, it is important to calculate more than just the simple accuracy estimate of $\\frac{num_{correct}}{num_{total}}$. We need a confusion matrix to see how well we did within each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">msg</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pred</th>\n",
       "      <th>ham</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flag</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>ham</td>\n",
       "      <td>940</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>spam</td>\n",
       "      <td>13</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      msg     \n",
       "pred  ham spam\n",
       "flag          \n",
       "ham   940   13\n",
       "spam   13  142"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.groupby(['flag', 'pred']).count().unstack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have visibility to the confusion matrix, we can calculate our various evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = 142\n",
    "TN = 940\n",
    "FP = 13\n",
    "FN = 13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate\n",
    "  \n",
    "It is important to note that the evaluation criteria are with respect to what we as researchers label as **positive** or **negative**. Is a true positive a correctly labeled `ham` message or is it `spam`? Based on how Python printed the confusion matrix, it looks like `ham` is the **true** label. With this in mind, it is better to think of your calculations in sentence form to get clearer insights.\n",
    "  \n",
    "As a baseline, we need to know the rate of `spam` and `ham` and see how a **super** naive model of \"everything is ham\" would do.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ham': 0.8673835125448028, 'spam': 0.13261648745519714}"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'd be correct about 86% correct with the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*How many messages were correctly labeled?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9765342960288809"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(TP + TN) / (TP + TN + FP + FN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Of the `spam` messages, how many were correctly classified? (sensitivity)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9161290322580645"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TP / (TP + FN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Of the messages marked as `spam`, how many actually were `spam`?  (precision)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9161290322580645"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TP / (TP + FP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Of the `ham` messages, how many were correctly classified? (specificity)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9863588667366212"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TN / (TN + FP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "  \n",
    "Overall, the classifier performed pretty well, with a precision and sensitivity for `spam` at close to 92%. The preprocessing steps likely had a strong influence on the performance. Removing variations in capitalization with the `.lower()` method helps to concentrate signal. Similarly, making sure there were similar proportions of `spam` in both training and test allowed the algorithm to learn in a realistic setting.  \n",
    "  \n",
    "We can explore the messages we incorrectly labeled. We can maybe find some insights that way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flag</th>\n",
       "      <th>msg</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>spam</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>869</td>\n",
       "      <td>spam</td>\n",
       "      <td>Hello. We need some posh birds and chaps to us...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1875</td>\n",
       "      <td>spam</td>\n",
       "      <td>Would you like to see my XXX pics they are so ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2413</td>\n",
       "      <td>spam</td>\n",
       "      <td>I don't know u and u don't know me. Send CHAT ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2742</td>\n",
       "      <td>spam</td>\n",
       "      <td>I don't know u and u don't know me. Send CHAT ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2821</td>\n",
       "      <td>spam</td>\n",
       "      <td>INTERFLORA - It's not too late to order Inter...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3360</td>\n",
       "      <td>spam</td>\n",
       "      <td>Sorry I missed your call let's talk when you h...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3419</td>\n",
       "      <td>spam</td>\n",
       "      <td>LIFE has never been this much fun and great un...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3530</td>\n",
       "      <td>spam</td>\n",
       "      <td>Xmas &amp; New Years Eve tickets are now on sale f...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3864</td>\n",
       "      <td>spam</td>\n",
       "      <td>Oh my god! I've found your number again! I'm s...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3991</td>\n",
       "      <td>spam</td>\n",
       "      <td>(Bank of Granite issues Strong-Buy) EXPLOSIVE ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4676</td>\n",
       "      <td>spam</td>\n",
       "      <td>Hi babe its Chloe, how r u? I was smashed on s...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5037</td>\n",
       "      <td>spam</td>\n",
       "      <td>You won't believe it but it's true. It's Incre...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>574</td>\n",
       "      <td>ham</td>\n",
       "      <td>Waiting for your call.</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>893</td>\n",
       "      <td>ham</td>\n",
       "      <td>Nutter. Cutter. Ctter. Cttergg. Cttargg. Ctarg...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>989</td>\n",
       "      <td>ham</td>\n",
       "      <td>Yun ah.the ubi one say if ü wan call by tomorr...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1082</td>\n",
       "      <td>ham</td>\n",
       "      <td>Can u get pic msgs to your phone?</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2196</td>\n",
       "      <td>ham</td>\n",
       "      <td>V-aluable. A-ffectionate. L-oveable. E-ternal....</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2236</td>\n",
       "      <td>ham</td>\n",
       "      <td>Si.como no?!listened2the plaid album-quite gd&amp;...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2389</td>\n",
       "      <td>ham</td>\n",
       "      <td>wiskey Brandy Rum Gin Beer Vodka Scotch Shampa...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3306</td>\n",
       "      <td>ham</td>\n",
       "      <td>Ee msg na poortiyagi odalebeku: Hanumanji 7 na...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3415</td>\n",
       "      <td>ham</td>\n",
       "      <td>No pic. Please re-send.</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3506</td>\n",
       "      <td>ham</td>\n",
       "      <td>life alle mone,eppolum oru pole allalo</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3728</td>\n",
       "      <td>ham</td>\n",
       "      <td>Aldrine, rakhesh ex RTM here.pls call.urgent.</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4703</td>\n",
       "      <td>ham</td>\n",
       "      <td>Anytime...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5046</td>\n",
       "      <td>ham</td>\n",
       "      <td>We have sent JD for Customer Service cum Accou...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      flag                                                msg  pred\n",
       "5     spam  FreeMsg Hey there darling it's been 3 week's n...   ham\n",
       "869   spam  Hello. We need some posh birds and chaps to us...   ham\n",
       "1875  spam  Would you like to see my XXX pics they are so ...   ham\n",
       "2413  spam  I don't know u and u don't know me. Send CHAT ...   ham\n",
       "2742  spam  I don't know u and u don't know me. Send CHAT ...   ham\n",
       "2821  spam  INTERFLORA - It's not too late to order Inter...   ham\n",
       "3360  spam  Sorry I missed your call let's talk when you h...   ham\n",
       "3419  spam  LIFE has never been this much fun and great un...   ham\n",
       "3530  spam  Xmas & New Years Eve tickets are now on sale f...   ham\n",
       "3864  spam  Oh my god! I've found your number again! I'm s...   ham\n",
       "3991  spam  (Bank of Granite issues Strong-Buy) EXPLOSIVE ...   ham\n",
       "4676  spam  Hi babe its Chloe, how r u? I was smashed on s...   ham\n",
       "5037  spam  You won't believe it but it's true. It's Incre...   ham\n",
       "574    ham                             Waiting for your call.  spam\n",
       "893    ham  Nutter. Cutter. Ctter. Cttergg. Cttargg. Ctarg...  spam\n",
       "989    ham  Yun ah.the ubi one say if ü wan call by tomorr...  spam\n",
       "1082   ham                  Can u get pic msgs to your phone?  spam\n",
       "2196   ham  V-aluable. A-ffectionate. L-oveable. E-ternal....  spam\n",
       "2236   ham  Si.como no?!listened2the plaid album-quite gd&...  spam\n",
       "2389   ham  wiskey Brandy Rum Gin Beer Vodka Scotch Shampa...  spam\n",
       "3306   ham  Ee msg na poortiyagi odalebeku: Hanumanji 7 na...  spam\n",
       "3415   ham                            No pic. Please re-send.  spam\n",
       "3506   ham             life alle mone,eppolum oru pole allalo  spam\n",
       "3728   ham      Aldrine, rakhesh ex RTM here.pls call.urgent.  spam\n",
       "4703   ham                                         Anytime...  spam\n",
       "5046   ham  We have sent JD for Customer Service cum Accou...  spam"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[test.flag != test.pred]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
